import sys                          # for program exit
import os                           # for file paths
import subprocess                   # for using command line
from typing import List, Tuple      # for type annotation
import numpy as np                  # for arrays
import matplotlib.pyplot as plt     # for plotting
import scipy.io.wavfile             # for using .wav files


# Function which given a time and a sampling rate, calculates the equivalent in samples
def convert_time_to_sample(time: float, fs: int = 16000) -> int:
    return int(time * fs)


# Function which converts a List of pitchmarks in time to a List of pitchmarks in samples
def convert_pitchmark_timestamps_to_samples(pitchmark_timestamps: List[float], fs: int) -> List[int]:
    pitchmarks_samples: List[int] = list()
    for pitchmark_timestamp in pitchmark_timestamps:
        pitchmarks_samples.append(convert_time_to_sample(pitchmark_timestamp, fs))
    return pitchmarks_samples


# Function which, given the path to an audio file, finds its pitch marks
def compute_pitchmarks(audio_file_path: str, pitchmark_tool: str = 'praat'):  # -> Tuple[List[float], List[float]]: TODO might not return freqs.

    # declare a list of floats for time stamps and another for the pitch/frequency at each timestamp
    timestamps: List[float] = list()
    frequencies: List[float] = list()

    if pitchmark_tool == 'aubio':
        # use aubio to compute the pitch of the .wav file
        aubio_output = subprocess.run(r'aubio-0.4.6-win64/bin/aubiopitch.exe -i ' + audio_file_path + ' -p yinfft',
                                      stdout=subprocess.PIPE)
        # capture the output from the command line and store it as a string
        aubio_string_output: str = aubio_output.stdout.decode('utf-8')

        for timestamp_frequency in aubio_string_output.strip().split('\r\n'):
            timestamp: float = float(timestamp_frequency.split(' ')[0])
            frequency: float = float(timestamp_frequency.split(' ')[1])

            timestamps.append(timestamp)
            if frequency == 0:
                frequencies.append(np.nan)
            else:
                frequencies.append(frequency)

        return timestamps, frequencies

    elif pitchmark_tool == 'praat':
        praat_executable_path: str = os.path.abspath(r"praat6049_win64\Praat.exe")
        praat_script_path: str = os.path.abspath(r"praat6049_win64\get_pitchmarks.praat")
        praat_wav_file_path: str = os.path.abspath(audio_file_path)

        # call the praat script 'get_pitchmarks.praat' from the command line with the absolute path of the wav file
        # as an argument
        subprocess.run(praat_executable_path + ' --run "' + praat_script_path + '" "' + praat_wav_file_path + '"',
                       stdout=subprocess.DEVNULL)

        # open the output text file generated by the praat script
        with open(r"praat6049_win64\pitch_list.txt", "r") as praat_output_file:
            # skip the first "time,pitch" line
            next(praat_output_file)
            # read the rest of the output file
            praat_output = praat_output_file.read()
            for timestamp_frequency in praat_output.strip().split():
                # timestamp: str, frequency: str = timestamp_frequency.split(',')   TODO annotate types
                timestamp, frequency = timestamp_frequency.split(',')
                if frequency != '--undefined--':    # TODO if undefined add timestamp, 0?
                    timestamps.append(float(timestamp))
                    frequencies.append(float(frequency))
                # TODO double check this - also how it relates to averaging the frequencies
                else:
                    timestamps.append(float(timestamp))
                    frequencies.append(np.nan)

        return timestamps, frequencies

    else:
        sys.exit('Invalid PitchMarking Tool Chosen!')


# Function which calculates the frequency of a wave from its pitchmarks
def calculate_frequency_from_pitchmarks(pitchmarks: List[float]) -> float:
    # the frequency, f of a wave can be calculated as 1 / T; where T is the period of the wave
    # the period, T can be calculated as the time between one crest (pitchmark) and the next
    # in order to get a more reliable value for T, the average time between all pitchmarks will be taken

    # iterate over all pitchmarks
    periods: List[float] = list()
    for i, pitchmark in enumerate(pitchmarks):
        if i+1 < len(pitchmarks):
            # calculate the period as being the time between the current pitchmark and the next
            period: float = pitchmarks[i+1] - pitchmarks[i]
            periods.append(period)
    # find the mean period over all calculated periods
    average_period: float = np.average(periods)

    # calculate the frequency using the formula f = 1 / T
    frequency: float = 1 / average_period

    return frequency


# Function which extracts a two period window from any given wave from its pitchmarks
def extract_two_period_window(all_audio_samples: List[np.ndarray], all_audio_samples_pitchmarks: List[List[int]]) -> List[np.ndarray]:
    all_audio_samples_two_period_windows: List[np.ndarray] = list()
    for i, audio_samples in enumerate(all_audio_samples):
        # find the index of the middle pitchmark of the current wave
        pitchmarks_midpoint: int = len(all_audio_samples_pitchmarks[i]) // 2
        # find which sample to start extracting from and till which to extract to get a two period window
        two_period_window_start: int = all_audio_samples_pitchmarks[i][pitchmarks_midpoint - 1]
        two_period_window_end: int = all_audio_samples_pitchmarks[i][pitchmarks_midpoint + 1]
        # TODO should I also save the midpoint to align for tapering?
        # extract the two period window # TODO [a:b+1]?
        two_period_window: np.ndarray = all_audio_samples[i][two_period_window_start:two_period_window_end]

        all_audio_samples_two_period_windows.append(two_period_window)

    return all_audio_samples_two_period_windows


def taper_audio(audio_samples: np.ndarray, window_type: str = 'hamming') -> np.ndarray:
    if window_type == 'hamming':
        tapered_window: np.ndarray = np.hamming(len(audio_samples))
    elif window_type == 'hanning':
        tapered_window: np.ndarray = np.hanning(len(audio_samples))
    elif window_type == 'triangular':
        tapered_window: np.ndarray = np.zeros(len(audio_samples))
        for i, _ in enumerate(tapered_window):
            tapered_window[i] = 1 - np.abs((i - ((len(audio_samples) - 1) / 2)) / (len(audio_samples) / 2))
        # win_len = len(audio_samples)
        # window = (1 - (np.abs(win_len - 1 - 2 * np.arange(1, win_len + 1, 1)) / (win_len + 1)))
    else:
        print('incorrect window type specified - using rectangular window')
        tapered_window: np.ndarray = np.ones(len(audio_samples))

    tapered_audio: np.ndarray = np.multiply(audio_samples, tapered_window)

    return tapered_audio


# Function which divides a given wave into sub waves by each pitchmark
def divide_wave_into_subwaves_by_pitchmarks(wave: np.ndarray, pitchmarks: List[int]) -> List[np.ndarray]:
    # declare a list of numpy arrays which will store all the subwaves of the original wave
    wave_subwaves: List[np.ndarray] = list()

    # add the first sub wave as the part of the wave from the beginning to the first pitchmark
    wave_subwaves.append(wave[:pitchmarks[0]])
    # iterate over all the pitchmarks
    for i, _ in enumerate(pitchmarks):
        # if this is not the last pitchmark
        if i+1 < len(pitchmarks):
            # create a new subwave from the current pitchmark to the next and add it to the list
            wave_subwaves.append(wave[pitchmarks[i]:pitchmarks[i+1]])
    # add the last sub wave as the part of the wave from the last pitchmark to the end of the wave
    wave_subwaves.append(wave[pitchmarks[-1]:])

    return wave_subwaves


# Function which does overlap and add (OLA) of 2 waves for a given number of samples
def overlap_add_waves(wave1: np.ndarray, wave2: np.ndarray, samples_to_overlap: int) -> np.ndarray:
    # extract the last samples_to_overlap samples from wave1
    # and the first samples_to_overlap samples from wave2
    # then OLA them.
    # then set overlap_added_wave to the prior overlap_added_wave,
    # concatenated with the overlapped and added part,
    # and then with the wave2_part wave.

    # set wave1_part to be the part of wave1 that will not be overlapped
    # [wave1 except the last samples_to_overlap elements]
    wave1_part = wave1[:-samples_to_overlap]
    # set wave1_part_to_ola to be the part of wave1 that will be overlapped and added
    # [last samples_to_overlap elements]
    wave1_part_to_ola = wave1[-samples_to_overlap:]

    # set wave2_part to be the part of wave2 that will not be overlapped
    # [wave2 except the first samples_to_overlap elements]
    wave2_part = wave2[samples_to_overlap:]
    # set wave2_part_to_ola to be the part of wave2 that will be overlapped and added
    # [first samples_to_overlap elements]
    wave2_part_to_ola = wave2[:samples_to_overlap]

    # calculate overlap_added_wave_part to be the element wise addition of the '_to_ola' arrays
    if samples_to_overlap == 0:
        overlap_added_wave_part: np.ndarray = np.empty(0)
    # if one of the waves has less samples than the number of samples that need to be overlapped
    elif samples_to_overlap > len(wave1_part_to_ola) or samples_to_overlap > len(wave2_part_to_ola):
        # then return the overlap of the entire wave (which will be less samples than the original sampels_to_overlap)
        return overlap_add_waves(wave1, wave2, min(len(wave1_part_to_ola), len(wave2_part_to_ola)))
    else:
        # TODO check that both have at least samples_to_overlap elements
        overlap_added_wave_part: np.ndarray = np.add(wave1_part_to_ola, wave2_part_to_ola)

    # set overlap_added_wave to the concatenation of:
    # the non-overlapped part of the original overlap_added_wave (ola_wave_part)
    # the overlap_added_wave_part (overlap_added_wave_part)
    # the non-overlapped part of the 'two period window' (two_period_window_part)
    overlap_added_wave = np.concatenate((wave1_part, overlap_added_wave_part, wave2_part))
    return overlap_added_wave


# Function which combines two audio waves using TD-PSOLA
def combine_audio_tdpsola(wave1_audio_samples: np.ndarray, wave2_audio_samples: np.ndarray,
                          first_wave_frequency: float, wave2_pitchmark_frequencies: List[float],
                          wave2_pitchmarks_time: List[float], wave2_two_period_window: np.ndarray,
                          fs: int):

    # divide wave 2 into a series of smaller waves, separating by pitchmarks
    wave2_pitchmarks_samples: List[int] = convert_pitchmark_timestamps_to_samples(wave2_pitchmarks_time, fs)    # TODO pass samples right away?
    wave2_subwaves: List[np.ndarray] = divide_wave_into_subwaves_by_pitchmarks(wave2_audio_samples, wave2_pitchmarks_samples)
    # taper all the subwaves in wave 2  # TODO do I also taper when adding zeros?
    wave2_subwaves_tapered: List[np.ndarray] = list()
    for wave2_subwave in wave2_subwaves:
        wave2_subwaves_tapered.append(taper_audio(wave2_subwave))

    # calculate the frequency of wave 1 and 2 using the calculate_frequency_from_pitchmarks function    # TODO
    wave1_frequency: float = first_wave_frequency
    # wave2_frequency: float = calculate_frequency_from_pitchmarks(wave2_pitchmarks_time) # TODO decide on how to properly calculate freq
    # wave2_frequency: float = np.mean(wave2_pitchmark_frequencies)   # TODO NaNs!
    wave2_frequency: float = np.nanmean(wave2_pitchmark_frequencies)  # TODO NaNs!
    # TODO
    if np.isnan(wave2_frequency):
        wave2_frequency = wave1_frequency
    # TODO
    # calculate the periodic time, T in seconds of each wave. (T = 1 / f)
    wave1_period_time: float = 1 / wave1_frequency
    wave2_period_time: float = 1 / wave2_frequency
    # convert the periodic time from seconds to number of samples. (samples = sampling rate * time in seconds)
    wave1_period_samples: int = convert_time_to_sample(wave1_period_time, fs)
    wave2_period_samples: int = convert_time_to_sample(wave2_period_time, fs)
    # calculate the difference in the periodic time (in number of samples) between the two waves
    period_difference_samples: int = np.abs(wave1_period_samples - wave2_period_samples)

    # if both waves have the same frequency # TODO is this also true for all consonants?
    if wave1_frequency == wave2_frequency:
        # simply concatenate their samples
        final_wave: np.ndarray = np.concatenate((wave1_audio_samples, wave2_audio_samples))
        return final_wave

    # if the first wave has a lower frequency than the next wave
    elif wave1_frequency < wave2_frequency:
        # add zeros between each pitch period of the second wave such that its frequency matches that of the first wave.
        # then possibly remove a pitch period from the end of the wave such that the wave's original duration is kept.

        # the number of zeroes to add between each pitch period
        number_of_zeroes: int = period_difference_samples

        # total number of zeroes (samples) that will be added, i.e. by how many samples the duration will increase.
        total_zeroes_added: int = (len(wave2_subwaves_tapered) - 1) * number_of_zeroes
        # the total number of samples that make up the subwaves (initially the entire wave)
        total_samples_in_subwaves: int = 0
        for subwave in wave2_subwaves_tapered:
            total_samples_in_subwaves += len(subwave)

        # iterate until the length of the remaining tapered subwaves plus the number of zeroes that will be added
        # is no longer greater than the original length of the wave plus half the duration of the last subwave
        while (total_samples_in_subwaves + total_zeroes_added) > (len(wave2_audio_samples) + (0.5 * len(wave2_subwaves[-1]))):
        # while total_zeroes_added > (0.5 * len(wave2_subwaves_tapered[-1])): # TODO
            # if the duration was greater, pop the last subwave
            wave2_subwaves_tapered.pop(-1)
            # recompute the total number of zeroes that will be added between the subwaves
            total_zeroes_added = (len(wave2_subwaves_tapered) - 1) * number_of_zeroes
            # recompute the total number of samples in the remaining subwaves
            total_samples_in_subwaves: int = 0
            for subwave in wave2_subwaves_tapered:
                total_samples_in_subwaves += len(subwave)

        # initially set the final_wave to the first subwave
        final_wave: np.ndarray = wave2_subwaves_tapered[0]
        # iterate over the remaining subwaves
        for subwave in wave2_subwaves_tapered[1:]:
            # set the final_wave to the current final_wave, plus number_of_zeroes zeroes, plus the current subwave
            final_wave = np.concatenate((final_wave, np.zeros(number_of_zeroes), subwave))

        # set the final_wave to wave1 concatenated with the computed second wave
        final_wave = np.concatenate((wave1_audio_samples, final_wave))
        # return the final_wave
        return final_wave

    # if the first wave has a higher frequency than the next wave
    elif wave1_frequency > wave2_frequency:
        # overlap and add the second wave at its pitchmarks such that its frequency matches that of the first wave.
        # then add copies of the 'two period window' to the beginning of the wave
        # such that the wave's original duration is kept.

        # the number of samples to overlap and add
        samples_to_overlap: int = period_difference_samples

        # initially set the final_wave to the first subwave
        final_wave: np.ndarray = wave2_subwaves_tapered[0]
        # iterate over the remaining subwaves
        for subwave in wave2_subwaves_tapered[1:]:
            # set the final_wave to the OLA of the current final_wave and the current subwave
            final_wave = overlap_add_waves(final_wave, subwave, samples_to_overlap)

        # calculate how many samples were lost due to overlapping
        # samples_lost_in_overlap: int = (len(wave2_subwaves) - 1) * samples_to_overlap
        samples_lost_in_overlap: int = np.abs(len(wave2_audio_samples) - len(final_wave))

        # the number of cycles to add to the beginning of the wave to compensate for the samples lost during OLA
        number_of_cycles: int = int(round(samples_lost_in_overlap / len(wave2_two_period_window), 0))

        # add as many two period windows from the original wave as specified in number_of_cycles
        # to compensate for the loss of samples from overlapping
        for i in range(number_of_cycles):
            # final_wave = np.concatenate((wave2_two_period_window, final_wave))  #TODO do I taper the two period window?
            final_wave = np.concatenate((taper_audio(wave2_two_period_window), final_wave))

        final_wave = np.concatenate((wave1_audio_samples, final_wave))
        # return wave1 concatenated with the computed second wave
        return final_wave


def combine_all_audio_tdpsola(all_audio_file_paths: List[str]):
    # read all the audio samples from the provided audio files
    # also read the sampling frequency
    all_audio_samples: List[np.ndarray] = list()
    for audio_file_path in all_audio_file_paths:
        fs, audio_samples = scipy.io.wavfile.read(audio_file_path)
        all_audio_samples.append(audio_samples)

    # get the pitch marks for every audio file to be combined
    all_audio_samples_pitchmarks_time: List[List[float]] = list()
    all_audio_samples_pitchmarks_samples: List[List[int]] = list()
    all_audio_samples_pitchmark_frequencies: List[List[float]] = list()
    for audio_file_path in all_audio_file_paths:
        # audio_samples_pitchmarks_timestamps: List[float] = compute_pitchmarks(audio_file_path)
        # audio_samples_pitchmarks_timestamps: List[float], audio_samples_pitchmark_frequencies: List[float] = compute_pitchmarks(audio_file_path)
        # extract pitch marks and frequencies using compute_pitchmarks function
        audio_samples_pitchmarks_timestamps, audio_samples_pitchmark_frequencies = compute_pitchmarks(audio_file_path)
        # TODO keep this or samples?
        all_audio_samples_pitchmarks_time.append(audio_samples_pitchmarks_timestamps)
        # add extracted pitch marks to list
        all_audio_samples_pitchmarks_samples.append(convert_pitchmark_timestamps_to_samples(audio_samples_pitchmarks_timestamps, fs))
        # add extracted frequencies to list
        all_audio_samples_pitchmark_frequencies.append(audio_samples_pitchmark_frequencies)

    # extract a 2 period window from each audio sample
    # maybe I can also extract a List[int] for 3 timestamps of sample ? [0, mid, end] (or just the midpoint) for better tapering TODO
    all_audio_samples_two_period_windows: List[np.ndarray] =\
        extract_two_period_window(all_audio_samples, all_audio_samples_pitchmarks_samples)

    # use the combine_audio_tdpsola function to use TD-PSOLA to join each diphone to the next

    # initially set final_audio_samples to the first wave
    final_audio_samples: np.ndarray = all_audio_samples[0]
    # calculate the frequency of the first wave. all subsequent waves must approximately match this frequency
    # first_wave_frequency: float = calculate_frequency_from_pitchmarks(all_audio_samples_pitchmarks_time[0]) # TODO method?
    # first_wave_frequency: float = np.mean(all_audio_samples_pitchmark_frequencies[0])  # TODO
    first_wave_frequency: float = np.nanmean(all_audio_samples_pitchmark_frequencies[0])  # TODO
    if np.isnan(first_wave_frequency):
        first_wave_frequency = 120.0
    for i, audio_samples in enumerate(all_audio_samples[1:], start=1):
        # use the combine_audio_tdpsola function to combine final_audio_samples with the current audio_samples
        final_audio_samples = combine_audio_tdpsola(final_audio_samples, audio_samples,
                                                    first_wave_frequency, all_audio_samples_pitchmark_frequencies[i],
                                                    all_audio_samples_pitchmarks_time[i], all_audio_samples_two_period_windows[i],
                                                    fs)

    return final_audio_samples


def plot_wave_samples(audio_samples: np.ndarray, cycles_xs: List[float] = []):
    # plot the audio samples
    plt.plot(audio_samples)
    # label the axes
    plt.ylabel("Amplitude")
    plt.xlabel("Samples")
    # set the title
    plt.title("Audio Wave Samples")

    # plot the pitch marks as vertical lines
    for cycles_x in cycles_xs:
        plt.axvline(x=cycles_x, color='orange')

    # display the plot
    plt.show()


def plot_wave_time(audio_samples: np.ndarray, fs: int, cycles_xs: List[float] = []):
    # plot the audio samples
    timestamps = np.arange(len(audio_samples))
    timestamps = timestamps / fs
    plt.plot(timestamps, audio_samples)
    # label the axes
    plt.ylabel("Amplitude")
    plt.xlabel("Time")
    # set the title
    plt.title("Audio Wave in Time")

    # plot the pitch marks as vertical lines
    for cycles_x in cycles_xs:
        plt.axvline(x=cycles_x, color='orange')

    # display the plot
    plt.show()


if __name__ == '__main__':
    audio_file_path: str = r"diphones/sine_80Hz_0.2s.wav"
    audio_file_path2: str = r"diphones/sine_120Hz_0.2s.wav"
    audio_file_path3: str = r"diphones/sine_80Hz_0.2s.wav"

    final_audio_wave: np.ndarray = combine_all_audio_tdpsola([audio_file_path, audio_file_path2, audio_file_path3])

    # Plot test
    fs, audio_samples1 = scipy.io.wavfile.read(audio_file_path)
    fs, audio_samples2 = scipy.io.wavfile.read(audio_file_path2)
    fs, audio_samples3 = scipy.io.wavfile.read(audio_file_path3)

    # audio_samples_pitchmarks_timestamps, audio_samples_pitchmark_frequencies = compute_pitchmarks(audio_file_path3, 'aubio')
    # plot_wave_time(audio_samples3, fs, audio_samples_pitchmarks_timestamps)
    #
    # f = calculate_frequency_from_pitchmarks(audio_samples_pitchmarks_timestamps)

    print("Simply Concatenating Two Audio Files:")
    naive_concat: np.ndarray = np.concatenate((audio_samples1, audio_samples2, audio_samples3))
    plot_wave_samples(naive_concat)
    print("Result from using TD-PSOLA")
    plot_wave_samples(final_audio_wave)

    # write the output of TDPSOLA to disk as a .wav file
    scipy.io.wavfile.write(r'outputs\naive_concat.wav', 16000, naive_concat)
    scipy.io.wavfile.write(r'outputs\TD_PSOLA.wav', 16000, np.int16(final_audio_wave))
